<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<link rel="shortcut icon" href="myIcon.ico">
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />

<meta name="keywords" content="Wenbo Li, CSE, CUHK, The Chinese University of Hong Kong">
<meta name="description" content="Wenbo LI&#39;s home page">
<meta name="google-site-verification" content="X2QFrl-bPeg9AdlMt4VKT9v6MJUSTCf-SrY3CvKt4Zs" />
<link rel="stylesheet" href="jemdoc.css" type="text/css">
<title>Wenbo LI&#39;s Homepage</title>
<!-- Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-159069803-1', 'auto');
ga('send', 'pageview');
</script>
<!-- End Google Analytics -->
<!--
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-87320911-1', 'auto');
  ga('send', 'pageview');

</script>
-->
</head>
<body>
<div id="layout-content" style="margin-top:25px">
<table>
	<tbody>
		<tr>
			<td width="670">
				<div id="toptitle">
					<h1>Wenbo LI <font face="Arial">    李文博 </font></h1></div>

				<p>
					Email: <a href="mailto:fenglinglwb@gmail.com">fenglinglwb AT gmail DOT com</a><br>
				</p>
				<p>
					<a href="https://scholar.google.com/citations?user=foGn_TIAAAAJ&hl=en"> <img src="./pic/others/google_scholar_logo.png" height="30px"> </a>
					<a href="https://github.com/fenglinglwb"> <img src="./pic/others/github_logo.png" height="30px"> </a>
				</p>
				<p>
					 I'm planning a trip to Xinjiang soon to unwind and enjoy a change of pace. Any recommendations for must-try local dishes or places worth visiting? <!-- <font color="#FF9933"> </font> -->
				</p>
			</td>
			<td>
				<img src="./pic/WenboLI.jpg" border="0" width="220"><br>
			</td>
		</tr>
    </tbody>
</table>

<!--<h2>Biography [<a href="./CV-JinYueming.pdf">CV</a>]</h2>-->
<h2>Biography </h2>
<p>
	<!-- I am currently a research scientist at Huawei Noah's Ark Lab, but will be leaving at the end of July. -->
	I completed my Ph.D. in the CSE Department at the Chinese University of Hong Kong in 2023, under the supervision of <a href="https://jiaya.me/">Prof. Jiaya Jia</a>. 
	I received both my Bachelor's degree from the IEEE Pilot Class in 2016 and my Master's degree in 2019, under the supervision of <a href="https://scholar.google.com/citations?user=GtNuBJcAAAAJ&hl=zh-CN">Prof. Hongtao Lu</a>, from Shanghai Jiao Tong University.
	My research interests lie primarily in AIGC and low-level vision.
</p>



<h2>News</h2>
<ul>
	<li>
        Four papers are accepted by ICCV 2025</b>.
	</li>
	<li>
        Two papers are accepted by ICML 2025</b>.
	</li>
	<li>
        One paper is accepted by IJCAI 2025</b>.
	</li>
	<li>
        Eight papers are accepted by CVPR 2025</b>.
	</li>
	<li>
        One paper is accepted by ICLR 2025</b>.
	</li>
	<li>
        Three papers are accepted by AAAI 2025</b>.
	</li>
</ul>

<h2>Selected Work</h2>
<ul>
	<li>
        Intelligent multimodal agents: <a href='https://jarvisart.vercel.app'><b>JarvisArt</b></a> <img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/LYL1015/JarvisArt?style=social">, <a href='https://cvpr2025-jarvisir.github.io'><b>JarvisIR</b></a> <img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/LYL1015/JarvisIR?style=social">, and <a href='https://haoyuchen.com/RestoreAgent'><b>RestoreAgent</b></a>.
	</li>
	<li>
        Efficient image and video synthesis methods: <a href='https://jiangjiaxiu.github.io/lovic/'><b>LoViC</b></a>, <a href='https://jingjingrenabc.github.io/turbo2k/'><b>Turbo2K</b></a>, <a href='https://jshilong.github.io/flashvideo-page'><b>FlashVideo</b></a> <img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/FoundationVision/FlashVideo?style=social">, <a href='https://jingjingrenabc.github.io/ultrapixel'><b>UltraPixel</b></a> <img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/catcathh/ultrapixel?style=social">.
	</li>
	<li>
        Efficient controllable image and video generation method: <a href='https://pbihao.github.io/projects/controlnext/index.html'><b>ControlNeXt</b></a> <img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/dvlab-research/ControlNeXt?style=social">.
	</li>
	<li>
        Efficient diffusion-based image and video SR models: PocketSR, FlowSR, <a href='https://arxiv.org/abs/2506.23618'><b>TurboVSR</b></a>, <a href='https://arxiv.org/abs/2502.01993'><b>FluxSR</b></a>, <a href='https://arxiv.org/abs/2411.17106'><b>PassionSR</b></a>, etc.
	</li>
	<li>
        Our <a href='https://github.com/fenglinglwb/MAT'><b>MAT</b></a> <img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/fenglinglwb/MAT?style=social"> is selected in the <b>CVPR 2022 Best Paper Finalists</b>.
	</li>
</ul>

<!--
<h2> Selected Publications</h2>
<table id="tbPublications" width="100%" style="border-collapse:separate; border-spacing:0px 10px;">
	<tbody>

	<tr>
		<td><center><img width="250" src="./pic/papers/sdm.jpg"></center></td>
		<td>
			<font size="2">Image Inpainting via Iteratively Decoupled Probabilistic Modeling
			<br>
			<i><b>Wenbo Li</b>, Xin Yu, Kun Zhou, Yibing Song, Zhe Lin, Jiaya Jia</i>
			<br>
            		International Conference on Learning Representations (<b>ICLR</b>) 2024 (<b>Spotlight</b>)
			<br>
			[<a href='https://arxiv.org/abs/2212.02963'><b>paper</b></a>|<a href='https://github.com/fenglinglwb/SDM'><b>code</b></a>]  <img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/fenglinglwb/SDM?style=social">
		</td>
	</tr>

	<tr>
		<td><center><img width="250" src="./pic/papers/nerflix.jpg"></center></td>
		<td>
			<font size="2">NeRFLiX: High-Quality Neural View Synthesis by Learning a Degradation-Driven Inter-viewpoint MiXer
			<br>
			<i>Kun Zhou*, <b>Wenbo Li*</b>, Yi Wang, Tao Hu, Nianjuan Jiang, Xiaoguang Han, Jiangbo Lu</i>
			<br>
			IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>) 2023
			<br>
			[<a href='https://redrock303.github.io/nerflix/'><b>project</b></a>|<a href='https://arxiv.org/abs/2303.06919'><b>paper</b></a>|<a href='https://github.com/redrock303/NeRFLiX_CVPR2023'><b>code</b></a>] <img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/redrock303/NeRFLiX_CVPR2023?style=social">
		</td>
	</tr>


	<tr>
		<td><center><img width="250" src="./pic/papers/edt.jpg"></center></td>
		<td>
			<font size="2">On Efficient Transformer-Based Image Pre-training for Low-level Vision
			<br>
			<i><b>Wenbo Li</b>, Xin Lu, Jiangbo Lu, Xiangyu Zhang, Jiaya Jia</i>
			<br>
            International Joint Conference on Artificial Intelligence (<b>IJCAI</b>) 2023 
			<br>
			[<a href='https://arxiv.org/abs/2112.10175'><b>paper</b></a>|<a href='https://github.com/fenglinglwb/EDT'><b>code</b></a>]  <img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/fenglinglwb/EDT?style=social">
		</td>
	</tr>

	<tr>
		<td><center><img width="250" src="./pic/papers/mat.jpg"></center></td>
		<td>
			<font size="2">MAT: Mask-Aware Transformer for Large Hole Image Inpainting
			<br>
			<i><b>Wenbo Li</b>, Zhe Lin, Kun Zhou, Lu Qi, Yi Wang, Jiaya Jia</i>
			<br>
			IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>) 2022 (<b>Best Paper Finalists, Oral</b>)
			<br>
			[<a href='https://arxiv.org/abs/2203.15270'><b>paper</b></a>|<a href='https://github.com/fenglinglwb/MAT'><b>code</b></a>|<a href='https://www.youtube.com/watch?v=9foscNsObMA'><b>Media Report</b></a>|<a href='https://docs.google.com/presentation/d/190LNr2_d384OL92WGgfHwUkRUCpEIECy/edit?usp=sharing&ouid=115198583208219285057&rtpof=true&sd=true'><b>Slides</b></a>|<a href='https://drive.google.com/file/d/1Yjq6wqnA9CGDwGbeba51Sen76HnbaRnw/view?usp=sharing'><b>Poster</b></a>]  <img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/fenglinglwb/MAT?style=social">
		</td>
	</tr>

	<tr>
		<td><center><img width="250" src="./pic/papers/rta.jpg"></center></td>
		<td>
			<font size="2">Revisiting Temporal Alignment for Video Restoration
			<br>
			<i>Kun Zhou*, <b>Wenbo Li*</b>, Liying Lu, Xiaoguang Han, Jiangbo Lu</i>
			<br>
			IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>) 2022
			<br>
			[<a href='https://arxiv.org/abs/2111.15288'><b>paper</b></a>|<a href='https://github.com/redrock303/Revisiting-Temporal-Alignment-for-Video-Restoration'><b>code</b></a>]  <img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/redrock303/Revisiting-Temporal-Alignment-for-Video-Restoration?style=social">
		</td>
	</tr>

	<tr>
		<td><center><img width="250" src="./pic/papers/bebygan.jpg"></center></td>
		<td>
			<font size="2">Best-Buddy GANs for Highly Detailed Image Super-Resolution
			<br>
			<i><b>Wenbo Li*</b>, Kun Zhou*, Lu Qi, Liying Lu, Jiangbo Lu, Jiaya Jia</i>
			<br>
			Thirty-Sixth AAAI Conference on Artificial Intelligence (<b>AAAI</b>) 2022 (<b>Oral</b>)
			<br>
			[<a href='https://arxiv.org/abs/2103.15295'><b>paper</b></a>|<a href='https://github.com/dvlab-research/Simple-SR'><b>code</b></a>]  <img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/dvlab-research/Simple-SR?style=social">
		</td>
	</tr>

	<tr>
		<td><center><img width="250" src="./pic/papers/masa.jpg"></center></td>
		<td>
			<font size="2">MASA-SR: Matching Acceleration and Spatial Adaptation for Reference-Based Image Super-Resolution
			<br>
			<i>Liying Lu*, <b>Wenbo Li*</b>, Xin Tao, Jiangbo Lu, Jiaya Jia</i>
			<br>
			IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>) 2021
			<br>
			[<a href='https://arxiv.org/abs/2106.02299'><b>paper</b></a>|<a href='https://github.com/dvlab-research/MASA-SR'><b>code</b></a>]  <img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/dvlab-research/MASA-SR?style=social">
		</td>
	</tr>

	<tr>
		<td><center><img width="250" src="./pic/papers/lapar.jpg"></center></td>
		<td>
			<font size="2">LAPAR: Linearly-Assembled Pixel-Adaptive Regression Network for Single Image Super-resolution and Beyond
			<br>
			<i><b>Wenbo Li*</b>, Kun Zhou*, Lu Qi, Nianjuan Jiang, Jiangbo Lu, Jiaya Jia</i>
			<br>
			Advances in Neural Information Processing Systems (<b>NeurIPS</b>) 2020
			<br>
			[<a href='https://arxiv.org/abs/2105.10422'><b>paper</b></a>|<a href='https://github.com/dvlab-research/Simple-SR'><b>code</b></a>]  <img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/dvlab-research/Simple-SR?style=social">
		</td>
	</tr>

	<tr>
		<td><center><img width="250" src="./pic/papers/mucan.jpg"></center></td>
		<td>
			<font size="2">MuCAN: Multi-correspondence Aggregation Network for Video Super-Resolution
			<br>
			<i><b>Wenbo Li</b>, Xin Tao, Taian Guo, Lu Qi, Jiangbo Lu, Jiaya Jia</i>
			<br>
			European Conference on Computer Vision (<b>ECCV</b>) 2020
			<br>
			[<a href='https://arxiv.org/abs/2007.11803'><b>paper</b></a>|<a href='https://github.com/dvlab-research/Simple-SR'><b>code</b></a>]  <img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/dvlab-research/Simple-SR?style=social">
		</td>
	</tr>

	<tr>
		<td><center><img width="250" src="./pic/papers/mspn.jpg"></center></td>
		<td>
			<font size="2">Rethinking on multi-stage networks for human pose estimation
			<br>
			<i><b>Wenbo Li</b>, Zhicheng Wang, Binyi Yin, Qixiang Peng, Yuming Du, Tianzi Xiao, Gang Yu, Hongtao Lu, Yichen Wei, Jian Sun</i>
			<br>
            Champion of ECCV 2018 COCO Keypoint Detection Challenge
			<br>
			[<a href='https://arxiv.org/abs/1901.00148'><b>paper</b></a>|<a href='https://github.com/megvii-research/MSPN'><b>code</b></a>]  <img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/megvii-research/MSPN?style=social">
		</td>
	</tr>

	<!--
	<tr>
		<td><center><img width="250" src="./pic/papers/tcl.jpg"></center></td>
		<td>
			<font size="2">Exploring Motion Ambiguity and Alignment for High-Quality Video Frame Interpolation
			<br>
			<i>Kun Zhou, <b>Wenbo Li</b>, Xiaoguang Han, Jiangbo Lu</i>
			<br>
			IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>) 2023
			<br>
			[<a href='https://arxiv.org/pdf/2203.10291'><b>paper</b></a>]
		</td>
	</tr>

	<tr>
		<td><center><img width="250" src="./pic/papers/idemoire.png"></center></td>
		<td>
			<font size="2">Towards Efficient and Scale-Robust Ultra-High-Definition Image Demoireing
			<br>
			<i>Xin Yu, Peng Dai, <b>Wenbo Li</b>, Lan Ma, Jiajun Shen, Jia Li, Xiaojuan Qi</i>
			<br>
			European Conference on Computer Vision (<b>ECCV</b>) 2022
			<br>
			[<a href='https://xinyu-andy.github.io/uhdm-page/'><b>project</b></a>|<a href='https://github.com/CVMI-Lab/UHDM'><b>code</b></a>] <img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/CVMI-Lab/UHDM?style=social">
		</td>
	</tr>

	<tr>
		<td><center><img width="250" src="./pic/papers/demoire.jpg"></center></td>
		<td>
			<font size="2">Video Demoireing with Relation-Based Temporal Consistency
			<br>
			<i>Peng Dai, Xin Yu, Lan Ma, Baoheng Zhang, Jia Li, <b>Wenbo Li</b>, Jiajun Shen, Xiaojuan Qi</i>
			<br>
			IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>) 2022
			<br>
			[<a href='https://arxiv.org/abs/2204.02957'><b>paper</b></a>|<a href='https://github.com/CVMI-Lab/VideoDemoireing'><b>code</b></a>] <img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/CVMI-Lab/VideoDemoireing?style=social">

		</td>
	</tr>

    </tbody>
</table>
-->


<h2><font> Honors and Awards </font></h2>
<ul>
<!--<ul style="list-style-type:none">
<p style="margin-left: 0px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><font size="3"><meta charset="utf-8">-->
    <li>
	Champion of MIPI 2025 Challenge on Deblurring for HVS/HybridEVS Camera
    </li>
    <li>
	Champion of AIM 2019 Challenge on Video Extreme Super-Resolution
    </li>
    <li>
	Champion of ECCV 2018 COCO Keypoint Detection Challenge
    </li>
    <li>
        Outstanding Graduate, SJTU
    </li>
    <li>
        Academic Excellence Scholarship, SJTU
    </li>
    <li>
        Wish Enterprise Scholarship, SJTU
    </li>
    <li>
        Fushou Li Enterprise Scholarship, SJTU
    </li>
    <!--  </font> </p> -->
</ul>

<h2><font> Academic Service </font></h2>
<ul>
    <!--  <b>Journal Reviewer:</b></br> -->
    <li>
    TPAMI, IJCV, TIP
    </li>

    <!-- <b>Conference Reviewer:</b></br> -->
    <li>
    ICML, ICLR, NeurIPS, CVPR, ICCV, ECCV, AAAI, IJCAI
    </li>
</ul>

</br>
</br>

<p align=right>
	<a class="pull-right" href="#">
    <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=wFmme877sPr9Bi-O6mxYxCQ5d5gLMou51e3Rf9vVPyQ&cl=ffffff&w=a"></script>
	</a>
</p>

<!--
<p><center><font>
        <br>&copy; Wenbo LI | Last updated: Apr. 2022 | <a href="photography/index.html">.</a> </font></center>
</p>
-->

</div>
</body>
</html>
